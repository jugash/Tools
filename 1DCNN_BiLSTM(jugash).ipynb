{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "1DCNN-BiLSTM(jugash).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jugash/Tools/blob/master/1DCNN_BiLSTM(jugash).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrVAWFk-rSlZ",
        "outputId": "273bbed0-ec63-47ef-bdc0-8c6403b7e860"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QySf-VvcVRY6",
        "outputId": "dfc5bc00-2d29-4590-aae0-f217d77e7a12"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import FastText\n",
        "#from gensim.models.wrappers import FastText\n",
        "from tqdm import tqdm\n",
        "from pprint import pprint\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt \n",
        "import io\n",
        "from sklearn.metrics import classification_report\n",
        "#%matplotlib inline\n",
        "\n",
        "#uploaded = files.upload()\n",
        "data_path = '/content/drive/My Drive/DataScience/data.txt'\n",
        "f = open(data_path, \"r\")\n",
        "\n",
        "#print(Sentences[2][1])\n",
        "df = pd.DataFrame()\n",
        "Sentences=[]\n",
        "count=0\n",
        "for s in f:\n",
        "    a=0\n",
        "    d=[]\n",
        "    count+=1\n",
        "    if \";\" in s:\n",
        "        '''if s.count(';') != 2:   Finding number of wrongly formatted lines\n",
        "            print(count)'''\n",
        "        b = s.split(\";\")\n",
        "        b[2] = b[2].lower()\n",
        "    #print(len(b[2]))\n",
        "        for x in range(len(b[2])):\n",
        "            if (b[2][x] == '.' or b[2][x] == '?' or b[2][x] == '!' or b[2][x] == 'â€¦'):\n",
        "                d.append(b[2][a:x])\n",
        "                a=x+1\n",
        "        df.loc[count, \"Name\"] = b[1]\n",
        "        df.loc[count, \"Utterance\"] = b[2]\n",
        "\n",
        "\n",
        "        for x in range(len(d)):\n",
        "            sent = d[x].translate({ord(i): None for i in ',-.'})\n",
        "            Sentences.append(sent.split()) # Need to remove non-alphabetical characters from the lists\n",
        "\n",
        "#df.to_csv('DataTable.csv')\n",
        "#print(Sentences)\n",
        "\n",
        "df['Name'] = df['Name'].replace(['Hero', 'Varun', ' Varunu', '06-18:08:Varun', 'varun', ' Varun'], 'Varun')\n",
        "df['Name'] = df['Name'].replace(['Balraju', 'Bala Raju', 'bala Raju', 'Bala raju', ' Bala Raju'], 'Balraju')\n",
        "df['Name'] = df['Name'].replace(['Heroine', 'Jagadamba', 'J', 'Jagadhamba', 'Jagdamba', 'Jagadhmba', 'Jagdhamba', ' Jagadhamba', 'Jgadhamba', 'Jagadhama'], 'Jagadamba')\n",
        "df['Name'] = df['Name'].replace(['krishna', 'Krshna', 'Krishana', 'Kroshna'], 'Krishna')\n",
        "df['Name'] = df['Name'].replace(['Heroine father', 'Jagadamba father', 'J father', 'Guravayya', 'Guravayy', ' J father', 'Guravyya'], 'Guruvayya') \n",
        "df['Name'] = df['Name'].replace(['Heroine grandma', 'Jagadamba grandma', 'J Grand mother', 'Baamma', 'J Grand Mother', 'Grand Mother'], 'J grandma')\n",
        "df['Name'] = df['Name'].replace(['Boss'], 'Ramesh')\n",
        "df['Name'] = df['Name'].str.replace('J.s Grand Moyther', 'J grandma', regex=True)\n",
        "df['Name'] = df['Name'].str.replace('J.s Grand Mother', 'J grandma', regex=True)\n",
        "df['Name'] = df['Name'].str.replace('Jagadhamba.s Grand Mother', 'J grandma', regex=True)\n",
        "df['Name'] = df['Name'].str.replace('J.sGrand Mother', 'J grandma', regex=True)\n",
        "df['Name'] = df['Name'].str.replace('Heroin.s Grand Mother', 'J grandma', regex=True)\n",
        "df['Name'] = df['Name'].str.replace('Hero-in.s Father', 'Guruvayya', regex=True)\n",
        "df['Name'] = df['Name'].str.replace('Heroin.s Father', 'Guruvayya', regex=True)\n",
        "#AllNames = df['Name'].unique().tolist()\n",
        "\n",
        "Dialogues_by_Speaker = df.groupby(\"Name\")[\"Utterance\"].count().nlargest(40)\n",
        "print(Dialogues_by_Speaker.head(40))\n",
        "\n",
        "df.loc[:, 'Labels'] = \"Other\"\n",
        "df.loc[df['Name'] == 'Varun', 'Labels'] = \"Varun\"\n",
        "df.loc[df['Name'] == 'Balraju', 'Labels'] = \"Balraju\"\n",
        "df.loc[df['Name'] == 'Jagadamba', 'Labels'] = \"Jagadamba\"\n",
        "df.loc[df['Name'] == 'Krishna', 'Labels'] = \"Krishna\"\n",
        "df.loc[df['Name'] == 'Guruvayya', 'Labels'] = \"Guruvayya\"\n",
        "df.loc[df['Name'] == 'Ramesh', 'Labels'] = \"Ramesh\"\n",
        "\n",
        "print(df.head(20))\n",
        "#pprint(AllNames)\n",
        "\n",
        "\n",
        "''' Gensim Word2Vec code \n",
        "start_time = time.time()\n",
        "\n",
        "model =  Word2Vec(sentences=Sentences, size=100, window=5, min_count=3, workers=4, sg=0)\n",
        "print(f'Time taken : {(time.time() - start_time) / 60:.2f} mins')\n",
        "'''\n",
        "\n",
        "\n",
        "embedding_dim=300\n",
        "\n",
        "model = FastText(Sentences, size=embedding_dim, window=5, min_count=1, workers=4, sg=0)\n",
        "#model = FastText.load_fasttext_format(Sentences)\n",
        "print(len(model.wv.vocab.keys()))\n",
        "print(model.wv.vector_size)\n",
        "#print(model.wv.get_vector('assalu'))\n",
        "print(model.wv.most_similar('assalu'))\n",
        "model.wv.save_word2vec_format('FastTextVectorsFinal.txt', fvocab = 'Vocab')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name\n",
            "Varun            1232\n",
            "Jagadamba         715\n",
            "Krishna           660\n",
            "Balraju           400\n",
            "Guruvayya         232\n",
            "Ramesh            197\n",
            "Mahesh            168\n",
            "Ranga             162\n",
            "J grandma         132\n",
            "Nikhil            124\n",
            "Madhur            118\n",
            "SB                100\n",
            "Shobhan Babu       91\n",
            "Baali Reddy        86\n",
            "Sasmitha           73\n",
            "Puli               72\n",
            "Apsara             67\n",
            "SSK                67\n",
            "KS                 63\n",
            "Divya              61\n",
            "Rambabu            54\n",
            "J mother           51\n",
            "Simham             49\n",
            "Rangi              40\n",
            "Varun grandma      38\n",
            "Jack               37\n",
            "Sai Reddy          37\n",
            "Sash               36\n",
            "Kodi Raju          35\n",
            "Bhavani            34\n",
            "Varun father       34\n",
            "Sarayu             33\n",
            "Sree Reddy         33\n",
            "Kaveri             31\n",
            "Boo                30\n",
            "RSK                29\n",
            "Barbie             28\n",
            "EM                 28\n",
            "Roo                28\n",
            "Paidiraju          26\n",
            "Name: Utterance, dtype: int64\n",
            "               Name  ...     Labels\n",
            "1          Narrator  ...      Other\n",
            "3     Man1(Brahmin)  ...      Other\n",
            "4   Mediator woman1  ...      Other\n",
            "5          Narrator  ...      Other\n",
            "6     Man1(Brahmin)  ...      Other\n",
            "7               All  ...      Other\n",
            "8              Man2  ...      Other\n",
            "9   Mediator woman1  ...      Other\n",
            "10          unknown  ...      Other\n",
            "11            Varun  ...      Varun\n",
            "12          Balraju  ...    Balraju\n",
            "13    Man1(Brahmin)  ...      Other\n",
            "14            Varun  ...      Varun\n",
            "15        Jagadamba  ...  Jagadamba\n",
            "16            Varun  ...      Varun\n",
            "17        Jagadamba  ...  Jagadamba\n",
            "18            Varun  ...      Varun\n",
            "19        Jagadamba  ...  Jagadamba\n",
            "20        Jagadamba  ...  Jagadamba\n",
            "21            Varun  ...      Varun\n",
            "\n",
            "[20 rows x 3 columns]\n",
            "13658\n",
            "300\n",
            "[('chalu', 0.9999984502792358), ('chaalu', 0.9999984502792358), ('asalu', 0.9999984502792358), ('baalu', 0.9999983906745911), ('meekasalu', 0.9999983906745911), ('kavithalu', 0.9999983310699463), ('thalakaayalu', 0.9999983310699463), ('pooladhandalu', 0.9999983310699463), ('jalapaathalu', 0.9999983310699463), ('varasalu', 0.9999983310699463)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DSz2nJyaOcW"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "labels = df['Labels'].values\n",
        "sentences = df['Utterance'].values\n",
        "\n",
        "#categorical_labels = to_categorical(labels, num_classes=7)\n",
        "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, labels, test_size = 0.25, random_state=1000)\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "y_train = lb.fit_transform(y_train)\n",
        "y_test = lb.transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juwHtM0Uay2p"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words=13000, lower=True)\n",
        "tokenizer.fit_on_texts(sentences_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
        "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cYbNiKArMZm"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def pad_repeat(A, size=100):\n",
        "  return np.vstack([np.resize(A[i], size) for i in range(len(A))])\n",
        "\n",
        "maxlen = 100\n",
        "\n",
        "X_train=pad_repeat(X_train,maxlen)\n",
        "X_test=pad_repeat(X_test,maxlen)\n",
        "\n",
        "X_train = X_train[y_train.argmax(axis=1) != 4]\n",
        "y_train = y_train[y_train.argmax(axis=1) != 4]\n",
        "y_train = np.hstack([y_train[:,:4], y_train[:, 5:]])\n",
        "\n",
        "X_test = X_test[y_test.argmax(axis=1) != 4]\n",
        "y_test = y_test[y_test.argmax(axis=1) != 4]\n",
        "y_test = np.hstack([y_test[:,:4], y_test[:, 5:]])\n",
        "\n",
        "\n",
        "# X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "# X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07vls3VIa-KA"
      },
      "source": [
        "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
        "    vocab_size = len(word_index) + 1\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word]\n",
        "                embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
        "    \n",
        "    return embedding_matrix\n",
        "\n",
        "\n",
        "#uploaded=files.upload()\n",
        "embedding_matrix = create_embedding_matrix('FastTextVectorsFinal.txt', tokenizer.word_index, embedding_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIdUdS2lnaB7"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfL0TNcfbO2J"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "import sys\n",
        "\n",
        "class LossAndErrorPrintingCallback(keras.callbacks.Callback):\n",
        "    # def on_train_batch_end(self, batch, logs=None):\n",
        "    #     sys.stdout.write(\"\\rFor batch {}, loss is {:7.2f}.\".format(batch, logs[\"loss\"]))\n",
        "\n",
        "    # def on_test_batch_end(self, batch, logs=None):\n",
        "    #     sys.stdout.write(\"\\rFor batch {}, loss is {:7.2f}.\".format(batch, logs[\"loss\"]))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        sys.stdout.write(\"\\rEpoch finished {:d}.\".format(epoch))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg5AiBggsumo"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class EarlyStoppingAtMinLoss(keras.callbacks.Callback):\n",
        "    \"\"\"Stop training when the loss is at its min, i.e. the loss stops decreasing.\n",
        "\n",
        "  Arguments:\n",
        "      patience: Number of epochs to wait after min has been hit. After this\n",
        "      number of no improvement, training stops.\n",
        "  \"\"\"\n",
        "\n",
        "    def __init__(self, patience=0):\n",
        "        super(EarlyStoppingAtMinLoss, self).__init__()\n",
        "        self.patience = patience\n",
        "        # best_weights to store the weights at which the minimum loss occurs.\n",
        "        self.best_weights = None\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        # The number of epoch it has waited when loss is no longer minimum.\n",
        "        self.wait = 0\n",
        "        # The epoch the training stops at.\n",
        "        self.stopped_epoch = 0\n",
        "        # Initialize the best as infinity.\n",
        "        self.best = np.Inf\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current = logs.get(\"loss\")\n",
        "        if np.less(current, self.best):\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "            # Record the best weights if current results is better (less).\n",
        "            self.best_weights = self.model.get_weights()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                self.model.stop_training = True\n",
        "                print(\"Restoring model weights from the end of the best epoch.\")\n",
        "                self.model.set_weights(self.best_weights)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        if self.stopped_epoch > 0:\n",
        "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJOydInSNFJs",
        "outputId": "0fd67775-2695-435b-e198-dfddd382c6ea"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras import layers\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding,Dropout,SpatialDropout1D,Conv1D,MaxPooling1D,GRU,BatchNormalization\n",
        "from tensorflow.keras.layers import Input,Bidirectional,GlobalAveragePooling1D,GlobalMaxPooling1D,concatenate,LeakyReLU, Flatten\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import callbacks\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, \n",
        "                           weights=[embedding_matrix], \n",
        "                           input_length=maxlen, \n",
        "                           trainable=False))\n",
        "\n",
        "model.add(layers.Conv1D(10, kernel_size=3,kernel_regularizer=regularizers.l2(0.00001), padding='same'))\n",
        "model.add(layers.LeakyReLU(alpha=0.2))\n",
        "model.add(layers.MaxPool1D(pool_size=2))\n",
        "model.add(SpatialDropout1D(0.5))\n",
        "# model.add(Flatten())\n",
        "# model.add(layers.Embedding(vocab_size, embedding_dim, \n",
        "#                            weights=[embedding_matrix], \n",
        "#                            input_length=maxlen, \n",
        "#                            trainable=False))\n",
        "# model.add(layers.Conv1D(10, kernel_size=8,kernel_regularizer=regularizers.l2(0.00001), padding='same'))\n",
        "# model.add(layers.LeakyReLU(alpha=0.2))\n",
        "# model.add(layers.MaxPool1D(pool_size=2))\n",
        "# model.add(SpatialDropout1D(0.5))\n",
        "# model.add(Flatten())\n",
        "model.add(Bidirectional(LSTM(50,dropout=0.5, recurrent_dropout=0.5)))\n",
        "\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(6,activation='softmax'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 300)          3408000   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 100, 10)           9010      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 100, 10)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 50, 10)            0         \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 50, 10)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 100)               24400     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1010      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 66        \n",
            "=================================================================\n",
            "Total params: 3,442,486\n",
            "Trainable params: 34,486\n",
            "Non-trainable params: 3,408,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr3mak5VrMZ2",
        "outputId": "e763aeee-2119-41ad-e027-7a36c3873afd"
      },
      "source": [
        "# print(y_train.argmax(axis=1))\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=1000,\n",
        "                    verbose=False,\n",
        "                    validation_split=0.15,\n",
        "                    batch_size=128,\n",
        "                    callbacks=[LossAndErrorPrintingCallback()])\n",
        "\n",
        "'''loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For batch 3, loss is    1.65.Epoch finished 0. {'loss': 1.5727980136871338, 'accuracy': 0.36902573704719543, 'val_loss': 1.6529594659805298, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.64.Epoch finished 1. {'loss': 1.580381989479065, 'accuracy': 0.36351102590560913, 'val_loss': 1.6420763731002808, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.64.Epoch finished 2. {'loss': 1.576865792274475, 'accuracy': 0.35983455181121826, 'val_loss': 1.6390293836593628, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.64.Epoch finished 3. {'loss': 1.575448751449585, 'accuracy': 0.3602941036224365, 'val_loss': 1.6445332765579224, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.64.Epoch finished 4. {'loss': 1.5758699178695679, 'accuracy': 0.36764705181121826, 'val_loss': 1.6446917057037354, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.63.Epoch finished 5. {'loss': 1.575914740562439, 'accuracy': 0.3658088147640228, 'val_loss': 1.6278903484344482, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.65.Epoch finished 6. {'loss': 1.575008511543274, 'accuracy': 0.3616727888584137, 'val_loss': 1.6487482786178589, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.64.Epoch finished 7. {'loss': 1.5816550254821777, 'accuracy': 0.3616727888584137, 'val_loss': 1.6382591724395752, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.65.Epoch finished 8. {'loss': 1.5787872076034546, 'accuracy': 0.36672794818878174, 'val_loss': 1.6458961963653564, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.64.Epoch finished 9. {'loss': 1.574744462966919, 'accuracy': 0.3648897111415863, 'val_loss': 1.6386033296585083, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.65.Epoch finished 10. {'loss': 1.5745424032211304, 'accuracy': 0.3648897111415863, 'val_loss': 1.6484057903289795, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.65.Epoch finished 11. {'loss': 1.5764323472976685, 'accuracy': 0.3584558963775635, 'val_loss': 1.6474512815475464, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.64.Epoch finished 12. {'loss': 1.5710604190826416, 'accuracy': 0.3658088147640228, 'val_loss': 1.6432764530181885, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.64.Epoch finished 13. {'loss': 1.5724343061447144, 'accuracy': 0.35753676295280457, 'val_loss': 1.6403123140335083, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.65.Epoch finished 14. {'loss': 1.5740092992782593, 'accuracy': 0.36672794818878174, 'val_loss': 1.651527762413025, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.65.Epoch finished 15. {'loss': 1.5738352537155151, 'accuracy': 0.35983455181121826, 'val_loss': 1.6452711820602417, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.65.Epoch finished 16. {'loss': 1.5752202272415161, 'accuracy': 0.3648897111415863, 'val_loss': 1.6478675603866577, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.64.Epoch finished 17. {'loss': 1.5656373500823975, 'accuracy': 0.36672794818878174, 'val_loss': 1.643782138824463, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.66.Epoch finished 18. {'loss': 1.578641653060913, 'accuracy': 0.36672794818878174, 'val_loss': 1.6575932502746582, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.64.Epoch finished 19. {'loss': 1.572224736213684, 'accuracy': 0.3681066036224365, 'val_loss': 1.6420753002166748, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.64.Epoch finished 20. {'loss': 1.5728297233581543, 'accuracy': 0.3694852888584137, 'val_loss': 1.6426080465316772, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.64.Epoch finished 21. {'loss': 1.5754448175430298, 'accuracy': 0.3639705777168274, 'val_loss': 1.6424003839492798, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.65.Epoch finished 22. {'loss': 1.5719166994094849, 'accuracy': 0.3662683963775635, 'val_loss': 1.6474804878234863, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.65.Epoch finished 23. {'loss': 1.5756092071533203, 'accuracy': 0.3727022111415863, 'val_loss': 1.6500177383422852, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.65.Epoch finished 24. {'loss': 1.568579912185669, 'accuracy': 0.3602941036224365, 'val_loss': 1.6544855833053589, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.66.Epoch finished 25. {'loss': 1.567911148071289, 'accuracy': 0.37867647409439087, 'val_loss': 1.6619460582733154, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.65.Epoch finished 26. {'loss': 1.5671247243881226, 'accuracy': 0.3658088147640228, 'val_loss': 1.6492540836334229, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.66.Epoch finished 27. {'loss': 1.5660240650177002, 'accuracy': 0.36994484066963196, 'val_loss': 1.6586722135543823, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.65.Epoch finished 28. {'loss': 1.5743374824523926, 'accuracy': 0.3658088147640228, 'val_loss': 1.6502790451049805, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.65.Epoch finished 29. {'loss': 1.566980004310608, 'accuracy': 0.3704044222831726, 'val_loss': 1.647991418838501, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.67.Epoch finished 30. {'loss': 1.5724273920059204, 'accuracy': 0.3671875, 'val_loss': 1.671515941619873, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.68.Epoch finished 31. {'loss': 1.573377013206482, 'accuracy': 0.3671875, 'val_loss': 1.6769317388534546, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.65.Epoch finished 32. {'loss': 1.5698215961456299, 'accuracy': 0.36121323704719543, 'val_loss': 1.6516648530960083, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.66.Epoch finished 33. {'loss': 1.5701017379760742, 'accuracy': 0.36305147409439087, 'val_loss': 1.662855625152588, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.66.Epoch finished 34. {'loss': 1.5716644525527954, 'accuracy': 0.35202205181121826, 'val_loss': 1.6638002395629883, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.66.Epoch finished 35. {'loss': 1.562064528465271, 'accuracy': 0.3759191036224365, 'val_loss': 1.6626819372177124, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.64.Epoch finished 36. {'loss': 1.5676790475845337, 'accuracy': 0.36672794818878174, 'val_loss': 1.6389341354370117, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.65.Epoch finished 37. {'loss': 1.5732144117355347, 'accuracy': 0.3570772111415863, 'val_loss': 1.652197003364563, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.66.Epoch finished 38. {'loss': 1.5665268898010254, 'accuracy': 0.37132352590560913, 'val_loss': 1.6637400388717651, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.64.Epoch finished 39. {'loss': 1.56232750415802, 'accuracy': 0.3662683963775635, 'val_loss': 1.6437419652938843, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.64.Epoch finished 40. {'loss': 1.5712597370147705, 'accuracy': 0.36351102590560913, 'val_loss': 1.64131760597229, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.64.Epoch finished 41. {'loss': 1.5721899271011353, 'accuracy': 0.37132352590560913, 'val_loss': 1.6439011096954346, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.65.Epoch finished 42. {'loss': 1.5701125860214233, 'accuracy': 0.3584558963775635, 'val_loss': 1.6498812437057495, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.65.Epoch finished 43. {'loss': 1.5690617561340332, 'accuracy': 0.36994484066963196, 'val_loss': 1.6451765298843384, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.65.Epoch finished 44. {'loss': 1.5758328437805176, 'accuracy': 0.3671875, 'val_loss': 1.6492925882339478, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.66.Epoch finished 45. {'loss': 1.5712122917175293, 'accuracy': 0.359375, 'val_loss': 1.6561976671218872, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.66.Epoch finished 46. {'loss': 1.5598870515823364, 'accuracy': 0.36764705181121826, 'val_loss': 1.6628706455230713, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.64.Epoch finished 47. {'loss': 1.5669382810592651, 'accuracy': 0.3639705777168274, 'val_loss': 1.6442946195602417, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.66.Epoch finished 48. {'loss': 1.5650713443756104, 'accuracy': 0.3658088147640228, 'val_loss': 1.6577733755111694, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.66.Epoch finished 49. {'loss': 1.5656092166900635, 'accuracy': 0.36351102590560913, 'val_loss': 1.6582107543945312, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.66.Epoch finished 50. {'loss': 1.5639145374298096, 'accuracy': 0.3658088147640228, 'val_loss': 1.6566575765609741, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.65.Epoch finished 51. {'loss': 1.5775885581970215, 'accuracy': 0.37086397409439087, 'val_loss': 1.6504400968551636, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.66.Epoch finished 52. {'loss': 1.5660966634750366, 'accuracy': 0.375, 'val_loss': 1.660971760749817, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.67.Epoch finished 53. {'loss': 1.5678377151489258, 'accuracy': 0.3681066036224365, 'val_loss': 1.667742371559143, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.66.Epoch finished 54. {'loss': 1.5719854831695557, 'accuracy': 0.35983455181121826, 'val_loss': 1.6641422510147095, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.66.Epoch finished 55. {'loss': 1.5687172412872314, 'accuracy': 0.3694852888584137, 'val_loss': 1.658712387084961, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.67.Epoch finished 56. {'loss': 1.5697698593139648, 'accuracy': 0.3648897111415863, 'val_loss': 1.6744779348373413, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.66.Epoch finished 57. {'loss': 1.557531476020813, 'accuracy': 0.3625919222831726, 'val_loss': 1.6634578704833984, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.67.Epoch finished 58. {'loss': 1.5689458847045898, 'accuracy': 0.3648897111415863, 'val_loss': 1.670035719871521, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.67.Epoch finished 59. {'loss': 1.5678452253341675, 'accuracy': 0.36121323704719543, 'val_loss': 1.6705496311187744, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.67.Epoch finished 60. {'loss': 1.5636566877365112, 'accuracy': 0.3662683963775635, 'val_loss': 1.671459674835205, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.67.Epoch finished 61. {'loss': 1.5648159980773926, 'accuracy': 0.36994484066963196, 'val_loss': 1.665633201599121, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.68.Epoch finished 62. {'loss': 1.5707908868789673, 'accuracy': 0.3759191036224365, 'val_loss': 1.6823221445083618, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.66.Epoch finished 63. {'loss': 1.5671088695526123, 'accuracy': 0.37867647409439087, 'val_loss': 1.6573492288589478, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.68.Epoch finished 64. {'loss': 1.571373701095581, 'accuracy': 0.3648897111415863, 'val_loss': 1.6752501726150513, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.67.Epoch finished 65. {'loss': 1.565085530281067, 'accuracy': 0.36994484066963196, 'val_loss': 1.6675759553909302, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.68.Epoch finished 66. {'loss': 1.5653753280639648, 'accuracy': 0.3662683963775635, 'val_loss': 1.6757895946502686, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.67.Epoch finished 67. {'loss': 1.5606448650360107, 'accuracy': 0.3648897111415863, 'val_loss': 1.6701933145523071, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.67.Epoch finished 68. {'loss': 1.5615118741989136, 'accuracy': 0.3694852888584137, 'val_loss': 1.6729953289031982, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.67.Epoch finished 69. {'loss': 1.565218448638916, 'accuracy': 0.36534926295280457, 'val_loss': 1.6682908535003662, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.68.Epoch finished 70. {'loss': 1.5686571598052979, 'accuracy': 0.3648897111415863, 'val_loss': 1.6817582845687866, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.67.Epoch finished 71. {'loss': 1.5595793724060059, 'accuracy': 0.3671875, 'val_loss': 1.668089747428894, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.66.Epoch finished 72. {'loss': 1.5582895278930664, 'accuracy': 0.3685661852359772, 'val_loss': 1.6607004404067993, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.66.Epoch finished 73. {'loss': 1.561898946762085, 'accuracy': 0.3717830777168274, 'val_loss': 1.6633379459381104, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.67.Epoch finished 74. {'loss': 1.5611906051635742, 'accuracy': 0.3717830777168274, 'val_loss': 1.6708134412765503, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.66.Epoch finished 75. {'loss': 1.562546730041504, 'accuracy': 0.36902573704719543, 'val_loss': 1.6629563570022583, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.68.Epoch finished 76. {'loss': 1.5594969987869263, 'accuracy': 0.37316176295280457, 'val_loss': 1.684632420539856, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.67.Epoch finished 77. {'loss': 1.5597867965698242, 'accuracy': 0.37454044818878174, 'val_loss': 1.6700807809829712, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.67.Epoch finished 78. {'loss': 1.555489420890808, 'accuracy': 0.36902573704719543, 'val_loss': 1.6673672199249268, 'val_accuracy': 0.34545454382896423}\n",
            "For batch 3, loss is    1.68.Epoch finished 79. {'loss': 1.5637421607971191, 'accuracy': 0.36443015933036804, 'val_loss': 1.6769838333129883, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.68.Epoch finished 80. {'loss': 1.5550161600112915, 'accuracy': 0.36534926295280457, 'val_loss': 1.6771894693374634, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.68.Epoch finished 81. {'loss': 1.5592676401138306, 'accuracy': 0.36672794818878174, 'val_loss': 1.6763825416564941, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.69.Epoch finished 82. {'loss': 1.5578726530075073, 'accuracy': 0.3694852888584137, 'val_loss': 1.6864033937454224, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.68.Epoch finished 83. {'loss': 1.5625585317611694, 'accuracy': 0.3625919222831726, 'val_loss': 1.6846215724945068, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.69.Epoch finished 84. {'loss': 1.5528299808502197, 'accuracy': 0.35983455181121826, 'val_loss': 1.691909909248352, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.71.Epoch finished 85. {'loss': 1.551585078239441, 'accuracy': 0.36672794818878174, 'val_loss': 1.706641435623169, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.68.Epoch finished 86. {'loss': 1.5687974691390991, 'accuracy': 0.3602941036224365, 'val_loss': 1.6825240850448608, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.69.Epoch finished 87. {'loss': 1.5618810653686523, 'accuracy': 0.3727022111415863, 'val_loss': 1.691881537437439, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.70.Epoch finished 88. {'loss': 1.5572816133499146, 'accuracy': 0.36672794818878174, 'val_loss': 1.6964832544326782, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.70.Epoch finished 89. {'loss': 1.5522605180740356, 'accuracy': 0.3740808963775635, 'val_loss': 1.703365445137024, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.70.Epoch finished 90. {'loss': 1.5557494163513184, 'accuracy': 0.3681066036224365, 'val_loss': 1.6953773498535156, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.69.Epoch finished 91. {'loss': 1.5563201904296875, 'accuracy': 0.3671875, 'val_loss': 1.6920477151870728, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.69.Epoch finished 92. {'loss': 1.5574129819869995, 'accuracy': 0.3671875, 'val_loss': 1.6924731731414795, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.70.Epoch finished 93. {'loss': 1.5569974184036255, 'accuracy': 0.3625919222831726, 'val_loss': 1.6967436075210571, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.70.Epoch finished 94. {'loss': 1.5543066263198853, 'accuracy': 0.3717830777168274, 'val_loss': 1.7024023532867432, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.71.Epoch finished 95. {'loss': 1.5595630407333374, 'accuracy': 0.36351102590560913, 'val_loss': 1.7066161632537842, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.72.Epoch finished 96. {'loss': 1.5627037286758423, 'accuracy': 0.36534926295280457, 'val_loss': 1.7153009176254272, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.69.Epoch finished 97. {'loss': 1.556763768196106, 'accuracy': 0.36121323704719543, 'val_loss': 1.685624122619629, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.71.Epoch finished 98. {'loss': 1.5537978410720825, 'accuracy': 0.37454044818878174, 'val_loss': 1.707649827003479, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.70.Epoch finished 99. {'loss': 1.5473190546035767, 'accuracy': 0.3763786852359772, 'val_loss': 1.7035993337631226, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.72.Epoch finished 100. {'loss': 1.5479673147201538, 'accuracy': 0.36902573704719543, 'val_loss': 1.7206509113311768, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.72.Epoch finished 101. {'loss': 1.5589646100997925, 'accuracy': 0.375, 'val_loss': 1.715234637260437, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.72.Epoch finished 102. {'loss': 1.5605746507644653, 'accuracy': 0.3685661852359772, 'val_loss': 1.7153350114822388, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.70.Epoch finished 103. {'loss': 1.5612746477127075, 'accuracy': 0.37086397409439087, 'val_loss': 1.6995065212249756, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.70.Epoch finished 104. {'loss': 1.5531789064407349, 'accuracy': 0.3681066036224365, 'val_loss': 1.7016264200210571, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.70.Epoch finished 105. {'loss': 1.552032709121704, 'accuracy': 0.37775734066963196, 'val_loss': 1.702317476272583, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.71.Epoch finished 106. {'loss': 1.560985803604126, 'accuracy': 0.3579963147640228, 'val_loss': 1.7068049907684326, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.70.Epoch finished 107. {'loss': 1.556477427482605, 'accuracy': 0.36443015933036804, 'val_loss': 1.6961861848831177, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.71.Epoch finished 108. {'loss': 1.5559475421905518, 'accuracy': 0.36994484066963196, 'val_loss': 1.7101166248321533, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.69.Epoch finished 109. {'loss': 1.557871699333191, 'accuracy': 0.36764705181121826, 'val_loss': 1.6907196044921875, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.71.Epoch finished 110. {'loss': 1.5532984733581543, 'accuracy': 0.36305147409439087, 'val_loss': 1.7134308815002441, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.69.Epoch finished 111. {'loss': 1.56669020652771, 'accuracy': 0.3681066036224365, 'val_loss': 1.6935827732086182, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.71.Epoch finished 112. {'loss': 1.5580345392227173, 'accuracy': 0.3704044222831726, 'val_loss': 1.714884638786316, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.72.Epoch finished 113. {'loss': 1.5545767545700073, 'accuracy': 0.3681066036224365, 'val_loss': 1.7154927253723145, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.72.Epoch finished 114. {'loss': 1.5588299036026, 'accuracy': 0.3671875, 'val_loss': 1.7240190505981445, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.72.Epoch finished 115. {'loss': 1.551317572593689, 'accuracy': 0.3740808963775635, 'val_loss': 1.7222050428390503, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.72.Epoch finished 116. {'loss': 1.5534086227416992, 'accuracy': 0.37545955181121826, 'val_loss': 1.7201404571533203, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.72.Epoch finished 117. {'loss': 1.5477380752563477, 'accuracy': 0.36672794818878174, 'val_loss': 1.7157591581344604, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.71.Epoch finished 118. {'loss': 1.563535451889038, 'accuracy': 0.35891544818878174, 'val_loss': 1.7060590982437134, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.71.Epoch finished 119. {'loss': 1.5521126985549927, 'accuracy': 0.3694852888584137, 'val_loss': 1.7136008739471436, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.73.Epoch finished 120. {'loss': 1.5472898483276367, 'accuracy': 0.37454044818878174, 'val_loss': 1.7274757623672485, 'val_accuracy': 0.34545454382896423}\n",
            "For batch 3, loss is    1.70.Epoch finished 121. {'loss': 1.5546678304672241, 'accuracy': 0.37086397409439087, 'val_loss': 1.6960891485214233, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.69.Epoch finished 122. {'loss': 1.5586243867874146, 'accuracy': 0.3694852888584137, 'val_loss': 1.693956732749939, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.71.Epoch finished 123. {'loss': 1.5508474111557007, 'accuracy': 0.3736213147640228, 'val_loss': 1.7114945650100708, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.72.Epoch finished 124. {'loss': 1.550872564315796, 'accuracy': 0.36351102590560913, 'val_loss': 1.715972661972046, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.71.Epoch finished 125. {'loss': 1.5553117990493774, 'accuracy': 0.36994484066963196, 'val_loss': 1.707348108291626, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.68.Epoch finished 126. {'loss': 1.552082896232605, 'accuracy': 0.37224265933036804, 'val_loss': 1.6830179691314697, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.73.Epoch finished 127. {'loss': 1.5520671606063843, 'accuracy': 0.3694852888584137, 'val_loss': 1.7313809394836426, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.71.Epoch finished 128. {'loss': 1.5488706827163696, 'accuracy': 0.3740808963775635, 'val_loss': 1.7096961736679077, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.73.Epoch finished 129. {'loss': 1.5531615018844604, 'accuracy': 0.375, 'val_loss': 1.725817084312439, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.72.Epoch finished 130. {'loss': 1.5459768772125244, 'accuracy': 0.3727022111415863, 'val_loss': 1.7194530963897705, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.71.Epoch finished 131. {'loss': 1.5480698347091675, 'accuracy': 0.37316176295280457, 'val_loss': 1.7055009603500366, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.73.Epoch finished 132. {'loss': 1.5557301044464111, 'accuracy': 0.3717830777168274, 'val_loss': 1.7287288904190063, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.72.Epoch finished 133. {'loss': 1.5481938123703003, 'accuracy': 0.36672794818878174, 'val_loss': 1.7214128971099854, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.74.Epoch finished 134. {'loss': 1.5463157892227173, 'accuracy': 0.375, 'val_loss': 1.7436306476593018, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.75.Epoch finished 135. {'loss': 1.5565265417099, 'accuracy': 0.37086397409439087, 'val_loss': 1.7488293647766113, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.72.Epoch finished 136. {'loss': 1.5484628677368164, 'accuracy': 0.3704044222831726, 'val_loss': 1.722460150718689, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.73.Epoch finished 137. {'loss': 1.5558573007583618, 'accuracy': 0.3681066036224365, 'val_loss': 1.7301653623580933, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.73.Epoch finished 138. {'loss': 1.5496013164520264, 'accuracy': 0.3740808963775635, 'val_loss': 1.7287664413452148, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.72.Epoch finished 139. {'loss': 1.5492695569992065, 'accuracy': 0.36902573704719543, 'val_loss': 1.7160837650299072, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.73.Epoch finished 140. {'loss': 1.5485477447509766, 'accuracy': 0.3685661852359772, 'val_loss': 1.7261674404144287, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.72.Epoch finished 141. {'loss': 1.5570625066757202, 'accuracy': 0.36994484066963196, 'val_loss': 1.724496603012085, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.75.Epoch finished 142. {'loss': 1.554309606552124, 'accuracy': 0.37454044818878174, 'val_loss': 1.7472575902938843, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.76.Epoch finished 143. {'loss': 1.5485957860946655, 'accuracy': 0.37132352590560913, 'val_loss': 1.7607091665267944, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.75.Epoch finished 144. {'loss': 1.54934561252594, 'accuracy': 0.3681066036224365, 'val_loss': 1.7486330270767212, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.76.Epoch finished 145. {'loss': 1.551884412765503, 'accuracy': 0.37316176295280457, 'val_loss': 1.7634962797164917, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.80.Epoch finished 146. {'loss': 1.5544005632400513, 'accuracy': 0.36902573704719543, 'val_loss': 1.804256558418274, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.71.Epoch finished 147. {'loss': 1.5511680841445923, 'accuracy': 0.375, 'val_loss': 1.7140839099884033, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.74.Epoch finished 148. {'loss': 1.5496554374694824, 'accuracy': 0.3685661852359772, 'val_loss': 1.7386283874511719, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.73.Epoch finished 149. {'loss': 1.553431510925293, 'accuracy': 0.3681066036224365, 'val_loss': 1.7343093156814575, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.72.Epoch finished 150. {'loss': 1.5525035858154297, 'accuracy': 0.37132352590560913, 'val_loss': 1.7169851064682007, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.72.Epoch finished 151. {'loss': 1.5502512454986572, 'accuracy': 0.37086397409439087, 'val_loss': 1.7229666709899902, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.72.Epoch finished 152. {'loss': 1.5474846363067627, 'accuracy': 0.3727022111415863, 'val_loss': 1.72104811668396, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.69.Epoch finished 153. {'loss': 1.5462604761123657, 'accuracy': 0.375, 'val_loss': 1.6927777528762817, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.72.Epoch finished 154. {'loss': 1.5456435680389404, 'accuracy': 0.37775734066963196, 'val_loss': 1.719445824623108, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.71.Epoch finished 155. {'loss': 1.5469715595245361, 'accuracy': 0.36994484066963196, 'val_loss': 1.709667682647705, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.74.Epoch finished 156. {'loss': 1.5514031648635864, 'accuracy': 0.375, 'val_loss': 1.7360817193984985, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.69.Epoch finished 157. {'loss': 1.544631004333496, 'accuracy': 0.36672794818878174, 'val_loss': 1.6942417621612549, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.73.Epoch finished 158. {'loss': 1.5480165481567383, 'accuracy': 0.3671875, 'val_loss': 1.7341605424880981, 'val_accuracy': 0.3298701345920563}\n",
            "For batch 3, loss is    1.71.Epoch finished 159. {'loss': 1.5522990226745605, 'accuracy': 0.3685661852359772, 'val_loss': 1.7125509977340698, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.72.Epoch finished 160. {'loss': 1.5491877794265747, 'accuracy': 0.37132352590560913, 'val_loss': 1.721205234527588, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.74.Epoch finished 161. {'loss': 1.5416947603225708, 'accuracy': 0.3704044222831726, 'val_loss': 1.739243745803833, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.75.Epoch finished 162. {'loss': 1.5415871143341064, 'accuracy': 0.36994484066963196, 'val_loss': 1.7499576807022095, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.74.Epoch finished 163. {'loss': 1.5467653274536133, 'accuracy': 0.3717830777168274, 'val_loss': 1.743091344833374, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.77.Epoch finished 164. {'loss': 1.5461314916610718, 'accuracy': 0.3736213147640228, 'val_loss': 1.7704116106033325, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.75.Epoch finished 165. {'loss': 1.552885890007019, 'accuracy': 0.3704044222831726, 'val_loss': 1.752264142036438, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.76.Epoch finished 166. {'loss': 1.5458096265792847, 'accuracy': 0.3795955777168274, 'val_loss': 1.7565772533416748, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.77.Epoch finished 167. {'loss': 1.5466793775558472, 'accuracy': 0.36443015933036804, 'val_loss': 1.770208477973938, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.75.Epoch finished 168. {'loss': 1.5423054695129395, 'accuracy': 0.37132352590560913, 'val_loss': 1.74725341796875, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.76.Epoch finished 169. {'loss': 1.5434887409210205, 'accuracy': 0.3736213147640228, 'val_loss': 1.7605847120285034, 'val_accuracy': 0.3298701345920563}\n",
            "For batch 3, loss is    1.76.Epoch finished 170. {'loss': 1.5483492612838745, 'accuracy': 0.3671875, 'val_loss': 1.7571558952331543, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.78.Epoch finished 171. {'loss': 1.5403622388839722, 'accuracy': 0.3772977888584137, 'val_loss': 1.778516411781311, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.77.Epoch finished 172. {'loss': 1.5442144870758057, 'accuracy': 0.3782169222831726, 'val_loss': 1.7740143537521362, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.77.Epoch finished 173. {'loss': 1.5437134504318237, 'accuracy': 0.3694852888584137, 'val_loss': 1.7660781145095825, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.78.Epoch finished 174. {'loss': 1.5458122491836548, 'accuracy': 0.38005515933036804, 'val_loss': 1.7797802686691284, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.77.Epoch finished 175. {'loss': 1.5482096672058105, 'accuracy': 0.37316176295280457, 'val_loss': 1.7743051052093506, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.78.Epoch finished 176. {'loss': 1.5491029024124146, 'accuracy': 0.3727022111415863, 'val_loss': 1.7775176763534546, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.75.Epoch finished 177. {'loss': 1.5537301301956177, 'accuracy': 0.37086397409439087, 'val_loss': 1.7490662336349487, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.73.Epoch finished 178. {'loss': 1.541587471961975, 'accuracy': 0.37775734066963196, 'val_loss': 1.7336561679840088, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.76.Epoch finished 179. {'loss': 1.541908621788025, 'accuracy': 0.3759191036224365, 'val_loss': 1.763821005821228, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.76.Epoch finished 180. {'loss': 1.5428577661514282, 'accuracy': 0.36443015933036804, 'val_loss': 1.756666898727417, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.73.Epoch finished 181. {'loss': 1.5450241565704346, 'accuracy': 0.375, 'val_loss': 1.7312536239624023, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.77.Epoch finished 182. {'loss': 1.5444086790084839, 'accuracy': 0.37316176295280457, 'val_loss': 1.766564965248108, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.75.Epoch finished 183. {'loss': 1.5314669609069824, 'accuracy': 0.3625919222831726, 'val_loss': 1.749866247177124, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.72.Epoch finished 184. {'loss': 1.5493236780166626, 'accuracy': 0.3658088147640228, 'val_loss': 1.7205636501312256, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.73.Epoch finished 185. {'loss': 1.5417438745498657, 'accuracy': 0.3727022111415863, 'val_loss': 1.7266366481781006, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.73.Epoch finished 186. {'loss': 1.5507102012634277, 'accuracy': 0.36305147409439087, 'val_loss': 1.726394772529602, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.78.Epoch finished 187. {'loss': 1.545492172241211, 'accuracy': 0.3704044222831726, 'val_loss': 1.775365948677063, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.76.Epoch finished 188. {'loss': 1.5455957651138306, 'accuracy': 0.36213234066963196, 'val_loss': 1.7616777420043945, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.75.Epoch finished 189. {'loss': 1.5465402603149414, 'accuracy': 0.37086397409439087, 'val_loss': 1.7500827312469482, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.75.Epoch finished 190. {'loss': 1.5395283699035645, 'accuracy': 0.38005515933036804, 'val_loss': 1.7468816041946411, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.82.Epoch finished 191. {'loss': 1.5321404933929443, 'accuracy': 0.3828125, 'val_loss': 1.8214154243469238, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.74.Epoch finished 192. {'loss': 1.5427968502044678, 'accuracy': 0.3681066036224365, 'val_loss': 1.7396544218063354, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.77.Epoch finished 193. {'loss': 1.5344631671905518, 'accuracy': 0.36121323704719543, 'val_loss': 1.7704569101333618, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.75.Epoch finished 194. {'loss': 1.5473055839538574, 'accuracy': 0.3772977888584137, 'val_loss': 1.7534116506576538, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.77.Epoch finished 195. {'loss': 1.5398292541503906, 'accuracy': 0.37316176295280457, 'val_loss': 1.7696962356567383, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.76.Epoch finished 196. {'loss': 1.545980453491211, 'accuracy': 0.3772977888584137, 'val_loss': 1.7604281902313232, 'val_accuracy': 0.3298701345920563}\n",
            "For batch 3, loss is    1.75.Epoch finished 197. {'loss': 1.5506725311279297, 'accuracy': 0.37224265933036804, 'val_loss': 1.752927303314209, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.77.Epoch finished 198. {'loss': 1.5416314601898193, 'accuracy': 0.3704044222831726, 'val_loss': 1.773421049118042, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.78.Epoch finished 199. {'loss': 1.5431408882141113, 'accuracy': 0.37086397409439087, 'val_loss': 1.7756973505020142, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.81.Epoch finished 200. {'loss': 1.5444118976593018, 'accuracy': 0.3717830777168274, 'val_loss': 1.8087834119796753, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.74.Epoch finished 201. {'loss': 1.5494076013565063, 'accuracy': 0.3717830777168274, 'val_loss': 1.7369539737701416, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.79.Epoch finished 202. {'loss': 1.5431251525878906, 'accuracy': 0.37086397409439087, 'val_loss': 1.79387366771698, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.77.Epoch finished 203. {'loss': 1.543757677078247, 'accuracy': 0.36994484066963196, 'val_loss': 1.7711201906204224, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.77.Epoch finished 204. {'loss': 1.5411198139190674, 'accuracy': 0.3671875, 'val_loss': 1.7688292264938354, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.78.Epoch finished 205. {'loss': 1.5359407663345337, 'accuracy': 0.3740808963775635, 'val_loss': 1.7776341438293457, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.76.Epoch finished 206. {'loss': 1.5391688346862793, 'accuracy': 0.36305147409439087, 'val_loss': 1.7589677572250366, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.75.Epoch finished 207. {'loss': 1.5554314851760864, 'accuracy': 0.36305147409439087, 'val_loss': 1.7510067224502563, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.74.Epoch finished 208. {'loss': 1.5452321767807007, 'accuracy': 0.37454044818878174, 'val_loss': 1.737808346748352, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.75.Epoch finished 209. {'loss': 1.546698808670044, 'accuracy': 0.36764705181121826, 'val_loss': 1.754410743713379, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.77.Epoch finished 210. {'loss': 1.5328923463821411, 'accuracy': 0.38005515933036804, 'val_loss': 1.7663580179214478, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.78.Epoch finished 211. {'loss': 1.5344159603118896, 'accuracy': 0.37316176295280457, 'val_loss': 1.7845354080200195, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.74.Epoch finished 212. {'loss': 1.549402117729187, 'accuracy': 0.3671875, 'val_loss': 1.7388392686843872, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.79.Epoch finished 213. {'loss': 1.5420904159545898, 'accuracy': 0.37545955181121826, 'val_loss': 1.7870110273361206, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.78.Epoch finished 214. {'loss': 1.541595697402954, 'accuracy': 0.3685661852359772, 'val_loss': 1.7826282978057861, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.83.Epoch finished 215. {'loss': 1.5453521013259888, 'accuracy': 0.3763786852359772, 'val_loss': 1.8266433477401733, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.77.Epoch finished 216. {'loss': 1.5468636751174927, 'accuracy': 0.3694852888584137, 'val_loss': 1.7698841094970703, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.79.Epoch finished 217. {'loss': 1.5402473211288452, 'accuracy': 0.3740808963775635, 'val_loss': 1.7882031202316284, 'val_accuracy': 0.3298701345920563}\n",
            "For batch 3, loss is    1.75.Epoch finished 218. {'loss': 1.5379201173782349, 'accuracy': 0.36764705181121826, 'val_loss': 1.7473193407058716, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.76.Epoch finished 219. {'loss': 1.5376331806182861, 'accuracy': 0.3736213147640228, 'val_loss': 1.7583436965942383, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.76.Epoch finished 220. {'loss': 1.533674955368042, 'accuracy': 0.37683823704719543, 'val_loss': 1.7612673044204712, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.78.Epoch finished 221. {'loss': 1.5324954986572266, 'accuracy': 0.3759191036224365, 'val_loss': 1.7790980339050293, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.76.Epoch finished 222. {'loss': 1.5382713079452515, 'accuracy': 0.3671875, 'val_loss': 1.7622051239013672, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.80.Epoch finished 223. {'loss': 1.5331724882125854, 'accuracy': 0.3736213147640228, 'val_loss': 1.803511619567871, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.77.Epoch finished 224. {'loss': 1.5299140214920044, 'accuracy': 0.3671875, 'val_loss': 1.7659245729446411, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.79.Epoch finished 225. {'loss': 1.5406676530838013, 'accuracy': 0.36902573704719543, 'val_loss': 1.7859649658203125, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.78.Epoch finished 226. {'loss': 1.5440549850463867, 'accuracy': 0.37132352590560913, 'val_loss': 1.7767844200134277, 'val_accuracy': 0.3298701345920563}\n",
            "For batch 3, loss is    1.78.Epoch finished 227. {'loss': 1.531713843345642, 'accuracy': 0.3694852888584137, 'val_loss': 1.78431236743927, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.77.Epoch finished 228. {'loss': 1.5337625741958618, 'accuracy': 0.3625919222831726, 'val_loss': 1.7715848684310913, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.80.Epoch finished 229. {'loss': 1.5376759767532349, 'accuracy': 0.35983455181121826, 'val_loss': 1.8000129461288452, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.77.Epoch finished 230. {'loss': 1.5343058109283447, 'accuracy': 0.36672794818878174, 'val_loss': 1.7678256034851074, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.77.Epoch finished 231. {'loss': 1.5419929027557373, 'accuracy': 0.3681066036224365, 'val_loss': 1.773632287979126, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.79.Epoch finished 232. {'loss': 1.5356096029281616, 'accuracy': 0.37086397409439087, 'val_loss': 1.794411063194275, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.77.Epoch finished 233. {'loss': 1.535098910331726, 'accuracy': 0.37913602590560913, 'val_loss': 1.7682290077209473, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.76.Epoch finished 234. {'loss': 1.5370925664901733, 'accuracy': 0.3704044222831726, 'val_loss': 1.756698489189148, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.77.Epoch finished 235. {'loss': 1.5482341051101685, 'accuracy': 0.3625919222831726, 'val_loss': 1.770010232925415, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.75.Epoch finished 236. {'loss': 1.5401742458343506, 'accuracy': 0.3658088147640228, 'val_loss': 1.7501370906829834, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.78.Epoch finished 237. {'loss': 1.5368045568466187, 'accuracy': 0.36764705181121826, 'val_loss': 1.7773700952529907, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.76.Epoch finished 238. {'loss': 1.5373115539550781, 'accuracy': 0.37086397409439087, 'val_loss': 1.7551085948944092, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.76.Epoch finished 239. {'loss': 1.5344113111495972, 'accuracy': 0.38556984066963196, 'val_loss': 1.758764624595642, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.79.Epoch finished 240. {'loss': 1.5321475267410278, 'accuracy': 0.3671875, 'val_loss': 1.7872276306152344, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.77.Epoch finished 241. {'loss': 1.5294445753097534, 'accuracy': 0.37086397409439087, 'val_loss': 1.7736387252807617, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.80.Epoch finished 242. {'loss': 1.5377346277236938, 'accuracy': 0.3685661852359772, 'val_loss': 1.803262710571289, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.74.Epoch finished 243. {'loss': 1.5285636186599731, 'accuracy': 0.36764705181121826, 'val_loss': 1.741843342781067, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.79.Epoch finished 244. {'loss': 1.5414152145385742, 'accuracy': 0.37454044818878174, 'val_loss': 1.7896157503128052, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.81.Epoch finished 245. {'loss': 1.5344219207763672, 'accuracy': 0.37545955181121826, 'val_loss': 1.810228705406189, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.80.Epoch finished 246. {'loss': 1.5317283868789673, 'accuracy': 0.3759191036224365, 'val_loss': 1.796411156654358, 'val_accuracy': 0.34545454382896423}\n",
            "For batch 3, loss is    1.78.Epoch finished 247. {'loss': 1.531883716583252, 'accuracy': 0.3795955777168274, 'val_loss': 1.7792071104049683, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.78.Epoch finished 248. {'loss': 1.5382035970687866, 'accuracy': 0.36902573704719543, 'val_loss': 1.777897834777832, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.82.Epoch finished 249. {'loss': 1.5323524475097656, 'accuracy': 0.36994484066963196, 'val_loss': 1.8230104446411133, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.77.Epoch finished 250. {'loss': 1.5260928869247437, 'accuracy': 0.3704044222831726, 'val_loss': 1.773821473121643, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.80.Epoch finished 251. {'loss': 1.5401932001113892, 'accuracy': 0.37086397409439087, 'val_loss': 1.8018821477890015, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.86.Epoch finished 252. {'loss': 1.5421223640441895, 'accuracy': 0.36994484066963196, 'val_loss': 1.8595080375671387, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.80.Epoch finished 253. {'loss': 1.5304508209228516, 'accuracy': 0.3685661852359772, 'val_loss': 1.8040133714675903, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.82.Epoch finished 254. {'loss': 1.531742811203003, 'accuracy': 0.3648897111415863, 'val_loss': 1.8247138261795044, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.79.Epoch finished 255. {'loss': 1.531356692314148, 'accuracy': 0.3763786852359772, 'val_loss': 1.7926462888717651, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.81.Epoch finished 256. {'loss': 1.5336583852767944, 'accuracy': 0.3717830777168274, 'val_loss': 1.806054949760437, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.80.Epoch finished 257. {'loss': 1.5347446203231812, 'accuracy': 0.3685661852359772, 'val_loss': 1.8032947778701782, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.78.Epoch finished 258. {'loss': 1.542738914489746, 'accuracy': 0.3671875, 'val_loss': 1.7762106657028198, 'val_accuracy': 0.3298701345920563}\n",
            "For batch 3, loss is    1.81.Epoch finished 259. {'loss': 1.537543773651123, 'accuracy': 0.3694852888584137, 'val_loss': 1.8057581186294556, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.83.Epoch finished 260. {'loss': 1.5353604555130005, 'accuracy': 0.3685661852359772, 'val_loss': 1.8305379152297974, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.78.Epoch finished 261. {'loss': 1.533841609954834, 'accuracy': 0.375, 'val_loss': 1.7827365398406982, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.83.Epoch finished 262. {'loss': 1.528778076171875, 'accuracy': 0.36764705181121826, 'val_loss': 1.8267990350723267, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.80.Epoch finished 263. {'loss': 1.5288190841674805, 'accuracy': 0.37316176295280457, 'val_loss': 1.8040270805358887, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.81.Epoch finished 264. {'loss': 1.5227283239364624, 'accuracy': 0.3772977888584137, 'val_loss': 1.8133231401443481, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.83.Epoch finished 265. {'loss': 1.5340677499771118, 'accuracy': 0.3662683963775635, 'val_loss': 1.8289719820022583, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.82.Epoch finished 266. {'loss': 1.5356340408325195, 'accuracy': 0.3662683963775635, 'val_loss': 1.8184746503829956, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.81.Epoch finished 267. {'loss': 1.5365703105926514, 'accuracy': 0.3759191036224365, 'val_loss': 1.812700867652893, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.82.Epoch finished 268. {'loss': 1.5298385620117188, 'accuracy': 0.3759191036224365, 'val_loss': 1.8213255405426025, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.83.Epoch finished 269. {'loss': 1.5284255743026733, 'accuracy': 0.3782169222831726, 'val_loss': 1.8340237140655518, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.83.Epoch finished 270. {'loss': 1.5285660028457642, 'accuracy': 0.3828125, 'val_loss': 1.825057029724121, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.86.Epoch finished 271. {'loss': 1.537603497505188, 'accuracy': 0.3694852888584137, 'val_loss': 1.8558651208877563, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.84.Epoch finished 272. {'loss': 1.5233887434005737, 'accuracy': 0.3736213147640228, 'val_loss': 1.840070128440857, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.84.Epoch finished 273. {'loss': 1.5422886610031128, 'accuracy': 0.3671875, 'val_loss': 1.8389352560043335, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.80.Epoch finished 274. {'loss': 1.5396199226379395, 'accuracy': 0.3759191036224365, 'val_loss': 1.7975248098373413, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.85.Epoch finished 275. {'loss': 1.5273948907852173, 'accuracy': 0.37867647409439087, 'val_loss': 1.8461652994155884, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.82.Epoch finished 276. {'loss': 1.5389125347137451, 'accuracy': 0.36305147409439087, 'val_loss': 1.8242183923721313, 'val_accuracy': 0.34805193543434143}\n",
            "For batch 3, loss is    1.87.Epoch finished 277. {'loss': 1.5274381637573242, 'accuracy': 0.37683823704719543, 'val_loss': 1.8725837469100952, 'val_accuracy': 0.34545454382896423}\n",
            "For batch 3, loss is    1.84.Epoch finished 278. {'loss': 1.527730941772461, 'accuracy': 0.36902573704719543, 'val_loss': 1.8393139839172363, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.87.Epoch finished 279. {'loss': 1.5287524461746216, 'accuracy': 0.37132352590560913, 'val_loss': 1.8669410943984985, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.86.Epoch finished 280. {'loss': 1.5275129079818726, 'accuracy': 0.3795955777168274, 'val_loss': 1.8590842485427856, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.86.Epoch finished 281. {'loss': 1.5331186056137085, 'accuracy': 0.3717830777168274, 'val_loss': 1.858741044998169, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.85.Epoch finished 282. {'loss': 1.524827241897583, 'accuracy': 0.3763786852359772, 'val_loss': 1.8481636047363281, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.84.Epoch finished 283. {'loss': 1.534426212310791, 'accuracy': 0.37224265933036804, 'val_loss': 1.8411600589752197, 'val_accuracy': 0.34805193543434143}\n",
            "For batch 3, loss is    1.84.Epoch finished 284. {'loss': 1.5289182662963867, 'accuracy': 0.3736213147640228, 'val_loss': 1.8398207426071167, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.83.Epoch finished 285. {'loss': 1.5336875915527344, 'accuracy': 0.3639705777168274, 'val_loss': 1.8266953229904175, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.88.Epoch finished 286. {'loss': 1.5253437757492065, 'accuracy': 0.375, 'val_loss': 1.8759454488754272, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.86.Epoch finished 287. {'loss': 1.5314723253250122, 'accuracy': 0.36764705181121826, 'val_loss': 1.8638571500778198, 'val_accuracy': 0.34805193543434143}\n",
            "For batch 3, loss is    1.86.Epoch finished 288. {'loss': 1.5344055891036987, 'accuracy': 0.36534926295280457, 'val_loss': 1.8589255809783936, 'val_accuracy': 0.34805193543434143}\n",
            "For batch 3, loss is    1.88.Epoch finished 289. {'loss': 1.5364516973495483, 'accuracy': 0.3658088147640228, 'val_loss': 1.880523443222046, 'val_accuracy': 0.34805193543434143}\n",
            "For batch 3, loss is    1.84.Epoch finished 290. {'loss': 1.5293631553649902, 'accuracy': 0.3658088147640228, 'val_loss': 1.8420579433441162, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.81.Epoch finished 291. {'loss': 1.532908320426941, 'accuracy': 0.3759191036224365, 'val_loss': 1.8124068975448608, 'val_accuracy': 0.34545454382896423}\n",
            "For batch 3, loss is    1.80.Epoch finished 292. {'loss': 1.5259610414505005, 'accuracy': 0.37132352590560913, 'val_loss': 1.7970499992370605, 'val_accuracy': 0.34805193543434143}\n",
            "For batch 3, loss is    1.85.Epoch finished 293. {'loss': 1.5240215063095093, 'accuracy': 0.3795955777168274, 'val_loss': 1.8460376262664795, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.79.Epoch finished 294. {'loss': 1.5318424701690674, 'accuracy': 0.3763786852359772, 'val_loss': 1.787178635597229, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.82.Epoch finished 295. {'loss': 1.534334421157837, 'accuracy': 0.37316176295280457, 'val_loss': 1.8159135580062866, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.80.Epoch finished 296. {'loss': 1.5323039293289185, 'accuracy': 0.37683823704719543, 'val_loss': 1.80109703540802, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.85.Epoch finished 297. {'loss': 1.523180603981018, 'accuracy': 0.375, 'val_loss': 1.847132921218872, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.81.Epoch finished 298. {'loss': 1.5205274820327759, 'accuracy': 0.3694852888584137, 'val_loss': 1.81160569190979, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.83.Epoch finished 299. {'loss': 1.5279388427734375, 'accuracy': 0.36213234066963196, 'val_loss': 1.8268955945968628, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.79.Epoch finished 300. {'loss': 1.5371092557907104, 'accuracy': 0.36672794818878174, 'val_loss': 1.7918235063552856, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.85.Epoch finished 301. {'loss': 1.5279059410095215, 'accuracy': 0.3740808963775635, 'val_loss': 1.8503687381744385, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.83.Epoch finished 302. {'loss': 1.530137062072754, 'accuracy': 0.36994484066963196, 'val_loss': 1.8317497968673706, 'val_accuracy': 0.3246753215789795}\n",
            "For batch 3, loss is    1.82.Epoch finished 303. {'loss': 1.5278748273849487, 'accuracy': 0.37545955181121826, 'val_loss': 1.817452073097229, 'val_accuracy': 0.34805193543434143}\n",
            "For batch 3, loss is    1.82.Epoch finished 304. {'loss': 1.5302534103393555, 'accuracy': 0.3763786852359772, 'val_loss': 1.8182382583618164, 'val_accuracy': 0.34805193543434143}\n",
            "For batch 3, loss is    1.83.Epoch finished 305. {'loss': 1.5126070976257324, 'accuracy': 0.3717830777168274, 'val_loss': 1.8285858631134033, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.82.Epoch finished 306. {'loss': 1.5319887399673462, 'accuracy': 0.36994484066963196, 'val_loss': 1.8203907012939453, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.81.Epoch finished 307. {'loss': 1.528685450553894, 'accuracy': 0.37775734066963196, 'val_loss': 1.8113154172897339, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.81.Epoch finished 308. {'loss': 1.5275758504867554, 'accuracy': 0.36764705181121826, 'val_loss': 1.814741611480713, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.82.Epoch finished 309. {'loss': 1.5236337184906006, 'accuracy': 0.37224265933036804, 'val_loss': 1.8224245309829712, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.84.Epoch finished 310. {'loss': 1.5251516103744507, 'accuracy': 0.375, 'val_loss': 1.8355656862258911, 'val_accuracy': 0.34545454382896423}\n",
            "For batch 3, loss is    1.82.Epoch finished 311. {'loss': 1.5471405982971191, 'accuracy': 0.3625919222831726, 'val_loss': 1.8204340934753418, 'val_accuracy': 0.34545454382896423}\n",
            "For batch 3, loss is    1.86.Epoch finished 312. {'loss': 1.5145827531814575, 'accuracy': 0.37316176295280457, 'val_loss': 1.8580306768417358, 'val_accuracy': 0.34805193543434143}\n",
            "For batch 3, loss is    1.81.Epoch finished 313. {'loss': 1.5350847244262695, 'accuracy': 0.35753676295280457, 'val_loss': 1.8095413446426392, 'val_accuracy': 0.34545454382896423}\n",
            "For batch 3, loss is    1.85.Epoch finished 314. {'loss': 1.5303627252578735, 'accuracy': 0.3736213147640228, 'val_loss': 1.852746844291687, 'val_accuracy': 0.34545454382896423}\n",
            "For batch 3, loss is    1.83.Epoch finished 315. {'loss': 1.5257396697998047, 'accuracy': 0.3805147111415863, 'val_loss': 1.8275847434997559, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.84.Epoch finished 316. {'loss': 1.530853271484375, 'accuracy': 0.3736213147640228, 'val_loss': 1.839287281036377, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.84.Epoch finished 317. {'loss': 1.5192500352859497, 'accuracy': 0.37775734066963196, 'val_loss': 1.8380986452102661, 'val_accuracy': 0.3298701345920563}\n",
            "For batch 3, loss is    1.86.Epoch finished 318. {'loss': 1.5172585248947144, 'accuracy': 0.3727022111415863, 'val_loss': 1.862842082977295, 'val_accuracy': 0.3298701345920563}\n",
            "For batch 3, loss is    1.85.Epoch finished 319. {'loss': 1.5270315408706665, 'accuracy': 0.375, 'val_loss': 1.854953408241272, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.85.Epoch finished 320. {'loss': 1.5336400270462036, 'accuracy': 0.37086397409439087, 'val_loss': 1.8463048934936523, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.84.Epoch finished 321. {'loss': 1.5330827236175537, 'accuracy': 0.37086397409439087, 'val_loss': 1.8383708000183105, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.86.Epoch finished 322. {'loss': 1.5203166007995605, 'accuracy': 0.38235294818878174, 'val_loss': 1.857035517692566, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.82.Epoch finished 323. {'loss': 1.527487874031067, 'accuracy': 0.37775734066963196, 'val_loss': 1.8180456161499023, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.84.Epoch finished 324. {'loss': 1.5319342613220215, 'accuracy': 0.3685661852359772, 'val_loss': 1.8446310758590698, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.85.Epoch finished 325. {'loss': 1.532653570175171, 'accuracy': 0.37132352590560913, 'val_loss': 1.8464336395263672, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.83.Epoch finished 326. {'loss': 1.5271720886230469, 'accuracy': 0.36305147409439087, 'val_loss': 1.8285983800888062, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.85.Epoch finished 327. {'loss': 1.5166853666305542, 'accuracy': 0.3805147111415863, 'val_loss': 1.849202275276184, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.86.Epoch finished 328. {'loss': 1.5149017572402954, 'accuracy': 0.38694852590560913, 'val_loss': 1.859729290008545, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.82.Epoch finished 329. {'loss': 1.520054817199707, 'accuracy': 0.3759191036224365, 'val_loss': 1.8185594081878662, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.84.Epoch finished 330. {'loss': 1.5213497877120972, 'accuracy': 0.38327205181121826, 'val_loss': 1.8353147506713867, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.86.Epoch finished 331. {'loss': 1.5171658992767334, 'accuracy': 0.37454044818878174, 'val_loss': 1.8628708124160767, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.86.Epoch finished 332. {'loss': 1.5235928297042847, 'accuracy': 0.38005515933036804, 'val_loss': 1.861470341682434, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.89.Epoch finished 333. {'loss': 1.5249638557434082, 'accuracy': 0.3704044222831726, 'val_loss': 1.8900419473648071, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.86.Epoch finished 334. {'loss': 1.5270814895629883, 'accuracy': 0.3602941036224365, 'val_loss': 1.8646740913391113, 'val_accuracy': 0.34545454382896423}\n",
            "For batch 3, loss is    1.85.Epoch finished 335. {'loss': 1.5260281562805176, 'accuracy': 0.3727022111415863, 'val_loss': 1.8473293781280518, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.85.Epoch finished 336. {'loss': 1.5201809406280518, 'accuracy': 0.3704044222831726, 'val_loss': 1.8476203680038452, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.85.Epoch finished 337. {'loss': 1.5206780433654785, 'accuracy': 0.37086397409439087, 'val_loss': 1.84731924533844, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.85.Epoch finished 338. {'loss': 1.5308009386062622, 'accuracy': 0.37316176295280457, 'val_loss': 1.8525516986846924, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.83.Epoch finished 339. {'loss': 1.528438687324524, 'accuracy': 0.3772977888584137, 'val_loss': 1.8301334381103516, 'val_accuracy': 0.34545454382896423}\n",
            "For batch 3, loss is    1.86.Epoch finished 340. {'loss': 1.527836799621582, 'accuracy': 0.37775734066963196, 'val_loss': 1.8603951930999756, 'val_accuracy': 0.34025973081588745}\n",
            "For batch 3, loss is    1.87.Epoch finished 341. {'loss': 1.530043363571167, 'accuracy': 0.375, 'val_loss': 1.8711711168289185, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.84.Epoch finished 342. {'loss': 1.5160484313964844, 'accuracy': 0.3814338147640228, 'val_loss': 1.8442457914352417, 'val_accuracy': 0.34545454382896423}\n",
            "For batch 3, loss is    1.87.Epoch finished 343. {'loss': 1.5214736461639404, 'accuracy': 0.36994484066963196, 'val_loss': 1.865413784980774, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.84.Epoch finished 344. {'loss': 1.521135687828064, 'accuracy': 0.3828125, 'val_loss': 1.8391541242599487, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.88.Epoch finished 345. {'loss': 1.5193475484848022, 'accuracy': 0.3704044222831726, 'val_loss': 1.8829394578933716, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.83.Epoch finished 346. {'loss': 1.5220003128051758, 'accuracy': 0.3681066036224365, 'val_loss': 1.8308335542678833, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.90.Epoch finished 347. {'loss': 1.515659213066101, 'accuracy': 0.3818933963775635, 'val_loss': 1.900012493133545, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.83.Epoch finished 348. {'loss': 1.5188837051391602, 'accuracy': 0.3860294222831726, 'val_loss': 1.8336739540100098, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.86.Epoch finished 349. {'loss': 1.5226918458938599, 'accuracy': 0.37224265933036804, 'val_loss': 1.8631033897399902, 'val_accuracy': 0.34545454382896423}\n",
            "For batch 3, loss is    1.82.Epoch finished 350. {'loss': 1.5219531059265137, 'accuracy': 0.3772977888584137, 'val_loss': 1.8243496417999268, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.88.Epoch finished 351. {'loss': 1.5322974920272827, 'accuracy': 0.3717830777168274, 'val_loss': 1.876633644104004, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.86.Epoch finished 352. {'loss': 1.5227080583572388, 'accuracy': 0.38648897409439087, 'val_loss': 1.8612343072891235, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.85.Epoch finished 353. {'loss': 1.5129117965698242, 'accuracy': 0.3828125, 'val_loss': 1.8533931970596313, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.87.Epoch finished 354. {'loss': 1.527625322341919, 'accuracy': 0.3740808963775635, 'val_loss': 1.869088888168335, 'val_accuracy': 0.34285715222358704}\n",
            "For batch 3, loss is    1.84.Epoch finished 355. {'loss': 1.518431305885315, 'accuracy': 0.37867647409439087, 'val_loss': 1.8449702262878418, 'val_accuracy': 0.34545454382896423}\n",
            "For batch 3, loss is    1.82.Epoch finished 356. {'loss': 1.5202127695083618, 'accuracy': 0.3763786852359772, 'val_loss': 1.818589448928833, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.84.Epoch finished 357. {'loss': 1.5276108980178833, 'accuracy': 0.3681066036224365, 'val_loss': 1.8384426832199097, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.82.Epoch finished 358. {'loss': 1.525327205657959, 'accuracy': 0.37224265933036804, 'val_loss': 1.818720817565918, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.83.Epoch finished 359. {'loss': 1.5297006368637085, 'accuracy': 0.36534926295280457, 'val_loss': 1.8311853408813477, 'val_accuracy': 0.3298701345920563}\n",
            "For batch 3, loss is    1.86.Epoch finished 360. {'loss': 1.524692416191101, 'accuracy': 0.37775734066963196, 'val_loss': 1.85902738571167, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.84.Epoch finished 361. {'loss': 1.531566858291626, 'accuracy': 0.3694852888584137, 'val_loss': 1.8405145406723022, 'val_accuracy': 0.34545454382896423}\n",
            "For batch 3, loss is    1.86.Epoch finished 362. {'loss': 1.5197114944458008, 'accuracy': 0.375, 'val_loss': 1.8551185131072998, 'val_accuracy': 0.34805193543434143}\n",
            "For batch 3, loss is    1.87.Epoch finished 363. {'loss': 1.517773985862732, 'accuracy': 0.38556984066963196, 'val_loss': 1.874343991279602, 'val_accuracy': 0.33766233921051025}\n",
            "For batch 3, loss is    1.86.Epoch finished 364. {'loss': 1.5243607759475708, 'accuracy': 0.36902573704719543, 'val_loss': 1.8562536239624023, 'val_accuracy': 0.33246752619743347}\n",
            "For batch 3, loss is    1.88.Epoch finished 365. {'loss': 1.5164858102798462, 'accuracy': 0.37454044818878174, 'val_loss': 1.8786485195159912, 'val_accuracy': 0.3298701345920563}\n",
            "For batch 3, loss is    1.88.Epoch finished 366. {'loss': 1.5234899520874023, 'accuracy': 0.3717830777168274, 'val_loss': 1.880167007446289, 'val_accuracy': 0.3246753215789795}\n",
            "For batch 3, loss is    1.89.Epoch finished 367. {'loss': 1.51934814453125, 'accuracy': 0.3851102888584137, 'val_loss': 1.8883801698684692, 'val_accuracy': 0.3298701345920563}\n",
            "For batch 3, loss is    1.86.Epoch finished 368. {'loss': 1.527625322341919, 'accuracy': 0.3694852888584137, 'val_loss': 1.863759994506836, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.86.Epoch finished 369. {'loss': 1.5189260244369507, 'accuracy': 0.3727022111415863, 'val_loss': 1.8637443780899048, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.84.Epoch finished 370. {'loss': 1.5251429080963135, 'accuracy': 0.3759191036224365, 'val_loss': 1.838545560836792, 'val_accuracy': 0.33506494760513306}\n",
            "For batch 3, loss is    1.91.Epoch finished 371. {'loss': 1.5181939601898193, 'accuracy': 0.3772977888584137, 'val_loss': 1.909775972366333, 'val_accuracy': 0.3298701345920563}\n",
            "For batch 15, loss is    1.52."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnhGvrTItPWh",
        "outputId": "9fe8857d-422e-4a8c-e794-c05aed1f7350"
      },
      "source": [
        "from scipy import stats\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(x=X_test, batch_size=20)\n",
        "predictions.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating network...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(875, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlE4xYcrrMZ6",
        "outputId": "4f5d16e8-f67a-48c4-a84c-530e8b9d341d"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(875, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "4wR1eGcHrMZ6",
        "outputId": "a97d495f-b956-4a78-a839-4c86dc8c5472"
      },
      "source": [
        "# plt.plot(predictions)\n",
        "# plt.show()\n",
        "z=np.argmax(y_test, axis=1)\n",
        "z1=np.argmax(predictions, axis=1)\n",
        "plt.hist(z, density=True, bins=range(6), alpha=0.3)\n",
        "plt.hist(z1, density=True, bins=range(6), alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# X_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Io932QBVrMZ8",
        "outputId": "4cc988f3-d63a-4593-f4f8-4f351a1593fa"
      },
      "source": [
        "print(predictions.argmax(axis=1))\n",
        "print(stats.describe(predictions.argmax(axis=1)))\n",
        "print(y_test.argmax(axis=1))\n",
        "print(classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1)))\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "    #N = np.arrange(0, 50) #no of Epochs3624131977558136, 'val_loss': 1.6126309633255005, 'val_accuracy': 0.3463034927845001}\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    #plt.savefig(args[\"plot\"])\n",
        "\n",
        "plot_history(history)\n",
        "\n",
        "print(\"[INFO] serializing network and label binarizer...\")\n",
        "#model.save(args[\"model\"], save_format=\"h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 2 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5 5 5 5 2\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 2 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2 5 5 5 2 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 2 5 5 2 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
            "DescribeResult(nobs=875, minmax=(2, 5), mean=4.928, variance=0.2110572082379862, skewness=-6.220229644522873, kurtosis=36.69125683060112)\n",
            "[2 5 3 2 2 0 0 1 1 5 5 0 4 2 5 3 2 0 5 3 5 2 5 1 3 5 5 5 5 5 0 5 1 5 5 5 3\n",
            " 5 5 5 3 0 2 3 1 5 3 0 3 4 5 2 5 5 3 4 5 3 2 5 5 5 2 2 5 2 0 3 2 2 3 3 2 5\n",
            " 3 5 5 3 5 5 5 2 3 2 3 3 5 4 5 0 5 0 5 2 5 2 2 5 3 0 1 5 5 3 4 1 5 5 5 5 5\n",
            " 5 3 3 3 2 2 2 0 3 5 5 1 5 4 3 4 2 5 5 2 5 4 5 5 5 2 2 4 5 3 2 3 5 5 0 5 3\n",
            " 0 5 5 3 2 5 5 5 0 3 2 4 2 2 3 5 2 2 2 3 2 5 0 2 2 5 5 2 4 3 2 5 5 2 5 0 2\n",
            " 2 5 2 2 2 5 2 2 3 5 3 5 0 0 5 5 2 0 5 0 4 5 5 3 5 2 2 3 0 5 1 3 5 0 0 2 0\n",
            " 5 2 2 5 0 5 3 0 0 5 2 3 5 4 5 5 3 0 5 2 2 2 2 4 5 3 2 0 3 5 2 1 3 2 5 5 2\n",
            " 3 5 3 2 5 2 0 4 5 0 5 2 5 0 3 3 5 0 1 2 1 3 2 0 1 5 2 5 5 0 5 2 5 4 3 5 5\n",
            " 5 4 3 5 2 2 5 5 1 2 2 5 0 0 3 0 2 3 3 0 5 5 3 2 4 5 5 5 0 3 0 1 1 3 5 3 0\n",
            " 3 5 5 2 4 5 3 1 3 5 5 5 3 0 3 5 1 1 5 2 2 3 5 3 1 3 3 2 5 2 1 3 5 5 3 5 0\n",
            " 5 5 2 5 0 5 5 3 5 5 5 5 3 3 3 5 4 5 2 3 2 5 3 5 5 2 5 3 0 5 3 2 5 3 0 5 0\n",
            " 5 3 2 3 2 5 3 2 1 5 3 0 5 5 5 1 3 1 1 3 5 5 5 2 5 0 5 3 0 5 3 5 3 2 2 0 2\n",
            " 2 0 5 0 3 4 2 5 5 3 2 3 5 5 3 3 3 1 1 5 2 0 2 2 4 5 2 2 5 5 3 0 5 2 3 5 3\n",
            " 5 5 2 2 5 5 5 5 5 5 2 0 2 0 5 5 5 5 0 0 1 5 2 0 2 5 1 5 5 5 3 3 2 2 2 2 2\n",
            " 0 2 5 5 3 5 2 2 3 2 5 0 5 5 3 1 5 2 2 5 5 5 5 5 0 5 2 2 0 2 3 5 3 3 5 2 3\n",
            " 3 5 5 3 2 3 2 4 3 5 5 3 5 2 3 5 5 2 2 5 2 5 5 3 5 5 5 3 1 2 2 5 0 2 3 5 5\n",
            " 0 5 5 5 1 5 5 2 2 5 2 4 3 1 3 3 5 5 5 5 5 3 4 5 2 4 2 2 2 0 5 0 5 5 5 0 5\n",
            " 1 2 5 5 0 0 3 3 4 0 0 5 1 2 3 5 3 1 2 0 5 5 4 2 2 5 4 0 3 2 0 3 3 4 0 5 3\n",
            " 2 5 2 5 1 2 5 4 1 2 0 2 5 0 2 5 5 5 3 3 4 5 1 2 2 2 3 2 3 0 2 5 2 5 0 3 5\n",
            " 5 2 2 5 5 3 2 5 5 3 5 0 5 2 2 4 5 5 4 5 5 3 2 0 5 5 5 1 0 2 1 3 3 5 1 2 5\n",
            " 3 1 5 5 1 2 3 2 5 3 5 5 3 3 0 2 3 4 3 5 3 5 5 2 0 2 3 2 5 3 1 4 2 2 4 5 3\n",
            " 3 5 3 2 0 2 5 5 5 2 5 5 2 1 3 5 2 4 2 0 5 0 1 4 5 5 5 5 3 5 5 0 0 1 5 4 4\n",
            " 5 2 5 2 0 5 3 5 3 3 1 3 5 0 3 3 3 5 4 2 5 2 5 5 2 3 0 0 3 3 3 3 2 2 3 2 5\n",
            " 2 5 5 2 3 2 5 4 2 2 2 5 3 2 2 4 5 5 4 1 5 0 2 1]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        98\n",
            "           1       0.00      0.00      0.00        51\n",
            "           2       0.29      0.03      0.06       196\n",
            "           3       0.00      0.00      0.00       167\n",
            "           4       0.00      0.00      0.00        45\n",
            "           5       0.36      0.97      0.53       318\n",
            "\n",
            "    accuracy                           0.36       875\n",
            "   macro avg       0.11      0.17      0.10       875\n",
            "weighted avg       0.20      0.36      0.20       875\n",
            "\n",
            "[INFO] serializing network and label binarizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3OigsYdrMZ8"
      },
      "source": [
        "DIS=X_test[:1600, :99].reshape(-1,150,3)\n",
        "print(DIS.shape)\n",
        "plt.figure(figsize=(12,18))\n",
        "plt.imshow(DIS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyxJRV76rMZ9"
      },
      "source": [
        "from cv2 import resize\n",
        "import fastai\n",
        "from fastai.vision import *\n",
        "from fastai.callbacks import *\n",
        "\n",
        "class SaveFeatures():\n",
        "    def __init__(self, module):\n",
        "        self.hook = module.register_forward_hook(self.hook_fn)\n",
        "    def hook_fn(self, module, input, output):\n",
        "        self.features = torch.tensor(output,requires_grad=True).cuda()\n",
        "    def close(self):\n",
        "        self.hook.remove()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwWXrRQGuWUh"
      },
      "source": [
        "class FilterVisualizer():\n",
        "    def __init__(self, size=56, upscaling_steps=12, upscaling_factor=1.2):\n",
        "        self.size, self.upscaling_steps, self.upscaling_factor = size, upscaling_steps, upscaling_factor\n",
        "        self.model = models.vgg16_bn(pretrained=True).cuda().eval()\n",
        "        # set_trainable(self.model, False)\n",
        "\n",
        "    def visualize(self, layer, filter, lr=0.1, opt_steps=20, blur=None):\n",
        "        sz = self.size\n",
        "        img = np.uint8(np.random.uniform(150, 180, (sz, sz, 3)))/255  # generate random image\n",
        "        activations = SaveFeatures(list(self.model.children())[layer])  # register hook\n",
        "\n",
        "        for _ in range(self.upscaling_steps):  # scale the image up upscaling_steps times\n",
        "            train_tfms, val_tfms = tfms_from_model(vgg16, sz)\n",
        "            img_var = V(val_tfms(img)[None], requires_grad=True)  # convert image to Variable that requires grad\n",
        "            optimizer = torch.optim.Adam([img_var], lr=lr, weight_decay=1e-6)\n",
        "            for n in range(opt_steps):  # optimize pixel values for opt_steps times\n",
        "                optimizer.zero_grad()\n",
        "                self.model(img_var)\n",
        "                loss = -activations.features[0, filter].mean()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            img = val_tfms.denorm(img_var.data.cpu().numpy()[0].transpose(1,2,0))\n",
        "            self.output = img\n",
        "            sz = int(self.upscaling_factor * sz)  # calculate new image size\n",
        "            img = cv2.resize(img, (sz, sz), interpolation = cv2.INTER_CUBIC)  # scale image up\n",
        "            if blur is not None: img = cv2.blur(img,(blur,blur))  # blur image to reduce high frequency patterns\n",
        "        self.save(layer, filter)\n",
        "        activations.close()\n",
        "        \n",
        "    def save(self, layer, filter):\n",
        "        plt.imsave(\"layer_\"+str(layer)+\"_filter_\"+str(filter)+\".jpg\", np.clip(self.output, 0, 1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "kj2AHS1Yu9lW",
        "outputId": "16859036-7a41-4321-c7af-377651e606a5"
      },
      "source": [
        "layer = 40\n",
        "filter = 265\n",
        "\n",
        "FV = FilterVisualizer(size=56, upscaling_steps=12, upscaling_factor=1.2)\n",
        "FV.visualize(layer, filter, blur=5)\n",
        "\n",
        "img = PIL.Image.open(\"layer_\"+str(layer)+\"_filter_\"+str(filter)+\".jpg\")\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-818a4416ad1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mFV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFilterVisualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m56\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupscaling_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupscaling_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mFV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblur\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"layer_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_filter_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-b8734e6d5c20>\u001b[0m in \u001b[0;36mvisualize\u001b[0;34m(self, layer, filter, lr, opt_steps, blur)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m  \u001b[0;31m# generate random image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# register hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupscaling_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# scale the image up upscaling_steps times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx8zsLSCvBWs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}